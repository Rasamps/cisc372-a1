{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a1_s1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mRTnnY4mC_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#R: Comments beginning with \"R:\" are added by me for the purpose of the assignment.\n",
        "# download data (-q is the quiet mode)\n",
        "! wget -q https://www.dropbox.com/s/lhb1awpi769bfdr/test.csv?dl=1 -O test.csv\n",
        "! wget -q https://www.dropbox.com/s/gudb5eunj700s7j/train.csv?dl=1 -O train.csv\n",
        "#R: Brings both the train and test data sets into our local folder for use."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZw2TUxShOlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Using pandas assign the training data to a variable.\n",
        "Xy_train = pd.read_csv('train.csv', engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3krkRRVbCvnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot a correlation heat map to see features and their correlation with price_rating.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "corrmat = Xy_train.corr()\n",
        "plt.subplots(figsize=(12,9))\n",
        "sns.heatmap(corrmat, vmax=0.9, square=True)\n",
        "#A point to note is that the correlation heatmap doesn't provide information for categorical attributes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz7AZWHuVbA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot individual correlation plots for features I deemed well-correlated with price_rating\n",
        "#Compares accommodates feature & price_rating\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(Xy_train['accommodates'], Xy_train['price_rating'])\n",
        "plt.ylabel('price_rating', fontsize=13)\n",
        "plt.xlabel('accommodates', fontsize=13)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk518MKSXzZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot individual correlation plots for features I deemed well-correlated with price_rating\n",
        "#Compares bedrooms feature & price_rating\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(Xy_train['bedrooms'], Xy_train['price_rating'])\n",
        "plt.ylabel('price_rating', fontsize=13)\n",
        "plt.xlabel('bedrooms', fontsize=13)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrxXaVczX_FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot individual correlation plots for features I deemed well-correlated with price_rating\n",
        "#Compares beds feature & price_rating\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(Xy_train['beds'], Xy_train['price_rating'])\n",
        "plt.ylabel('price_rating', fontsize=13)\n",
        "plt.xlabel('beds', fontsize=13)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLU6d3L0YGsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot individual correlation plots for features I deemed well-correlated with price_rating\n",
        "#Compares square_feet feature & price_rating\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(Xy_train['square_feet'], Xy_train['price_rating'])\n",
        "plt.ylabel('price_rating', fontsize=13)\n",
        "plt.xlabel('square_feet', fontsize=13)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLiXvmoth9Ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#From the square_feet plot, it seems as though this column has many missing values...\n",
        "nonMissing = 0\n",
        "for i in range(0,len(Xy_train['square_feet'])):\n",
        "  if (Xy_train['square_feet'][i] >= 0):\n",
        "    nonMissing += 1\n",
        "print(\"The number of missing entries in the square_feet feature is:\",len(Xy_train['square_feet']) - nonMissing)\\\n",
        "#With how many missing values, it may not be worthwhile to interpret as the majority would all have\n",
        "#the same value depending on interpretation method. This wouldn't give my model much information gain."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFztwdf5Yn_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot individual correlation plots for features I deemed well-correlated with price_rating\n",
        "#Compares guests_included feature & price_rating\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(Xy_train['guests_included'], Xy_train['price_rating'])\n",
        "plt.ylabel('price_rating', fontsize=13)\n",
        "plt.xlabel('guests_included', fontsize=13)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i61u_a9JYuXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot individual correlation plots for features I deemed well-correlated with price_rating\n",
        "#Compares review_scores_cleanliness feature & price_rating\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(Xy_train['review_scores_cleanliness'], Xy_train['price_rating'])\n",
        "plt.ylabel('price_rating', fontsize=13)\n",
        "plt.xlabel('review_scores_cleanliness', fontsize=13)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrDtMwQTY2il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot individual correlation plots for features I deemed well-correlated with price_rating\n",
        "#Compares availability_30 feature & price_rating\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(Xy_train['availability_30'], Xy_train['price_rating'])\n",
        "plt.ylabel('price_rating', fontsize=13)\n",
        "plt.xlabel('availability_30', fontsize=13)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC65ok6NhaoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop outliers and fill in missing values for the features we care about.\n",
        "import numpy as np\n",
        "#Based on the correlation figure for the beds and bedrooms there was one extreme outlier.\n",
        "#We drop this so our model can 'train' better.\n",
        "Xy_train = Xy_train[Xy_train.beds != 20]\n",
        "Xy_train = Xy_train[Xy_train.bedrooms != 20]\n",
        "#We also drop the square_feet feature based on the previous investigations into it.\n",
        "Xy_train = Xy_train.drop(columns=['square_feet'])\n",
        "\n",
        "#Partition the training and testing data into separate variables as done in the sample script.\n",
        "X_train = Xy_train.drop(columns=['price_rating'])\n",
        "y_train = Xy_train[['price_rating']]\n",
        "X_test = pd.read_csv('test.csv', engine='python')\n",
        "testing_ids = X_test.Id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63lc6vth-0zQ",
        "colab_type": "code",
        "outputId": "39c9c838-f871-455a-cac6-04c37bc8311c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# model training and tuning\n",
        "#This script attempts to accomplish the classification problem at hand using a Support Vector Machine.\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.svm import SVC as svc\n",
        "\n",
        "#Based on the scatterplots, these were the decided upon numeric features. Only three were used in order to not overfit the model.\n",
        "numeric_features = ['bedrooms', 'accommodates', 'beds']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors = 3, weights = 'uniform')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "#Similarly, I did not want to overfit the model with categorical features and so selected the two which intuitively could make the most\n",
        "#sense in explaining the price level of an AirBnB listing.\n",
        "categorical_features = ['property_type', 'room_type']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant',fill_value=\"missing\")),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "#A standard preprocessor variable for applying transformations to different types of data.\n",
        "preprocessor = ColumnTransformer(\n",
        "               transformers = [\n",
        "                  ('num', numeric_transformer, numeric_features),\n",
        "                  ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "#Define that the classifier model to be used is an SVM for classification. i.e. svc.\n",
        "classif = Pipeline(\n",
        "          steps = [\n",
        "              ('preprocessor', preprocessor),\n",
        "              ('classifier', svc())])\n",
        "\n",
        "#Partitions the training and testing set by the selected attributes.\n",
        "X_train = X_train[[*numeric_features, *categorical_features]]\n",
        "X_test = X_test[[*numeric_features, *categorical_features]]\n",
        "\n",
        "#Possible hyperparameters include C, gamma and the kernel to be used.\n",
        "param_grid = {\n",
        "    'classifier__C': [10,50,80],\n",
        "    'classifier__gamma': [0.001,0.01,0.1],\n",
        "    'classifier__kernel': ['rbf'],\n",
        "    'preprocessor__num__imputer__n_neighbors': [3,4,5]\n",
        "}\n",
        "\n",
        "#Using the above \"param_grid\" we can search all possible combinations selecting the best set of hyperparameters\n",
        "#for our model to use. (Final Model: C = 80 / gamma = 0.1 / kernel = rbf)\n",
        "grid_search = GridSearchCV(\n",
        "   classif, param_grid, cv=5, verbose = 3, n_jobs = 3, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best hyperparameter set{}'.format(grid_search.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   40.9s\n",
            "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=3)]: Done 135 out of 135 | elapsed:  7.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best score 0.7002218163848484\n",
            "best hyperparameter set{'classifier__C': 80, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf', 'preprocessor__num__imputer__n_neighbors': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TA0p3tQaYHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction & generating the submission file\n",
        "#Predict the price rating for each test record. Create a csv file containing the test records Id and the predicted\n",
        "#price rating.\n",
        "y_pred = grid_search.predict(X_test)\n",
        "pd.DataFrame(\n",
        "    {'Id': testing_ids, 'price_rating':y_pred}).to_csv('a1submission1.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}